{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目背景\n",
    "项目来源于 kaggle 在 2013 年组织的一场比赛，它使用25000张（约543M）猫狗图片作为训练集，12500张(约271M)图片作为测试集，数据都是分辨率400x400左右的小图片，目标是识别测试集中的图片是猫还是狗。赛题网址：https://www.kaggle.com/c/dogs-vs-cats。\n",
    "\n",
    "目前 Leaderboard 上展示了 1314 支队伍的成绩，排名第一的 score 是 0.03302，Top2% 的成绩是 0.04357。本项目的最低要求是 kaggle Public Leaderboard 前 10%，即 0.06149。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题陈述\n",
    "深度学习中最突出的问题之一是图像分类。图像分类的目的是根据潜在的类别对特定的图像进行分类。图像分类的一个经典示例是在一组图像中识别猫和狗。\n",
    "\n",
    "本文将介绍如何在图像分类问题中实施迁移学习解决方案。主要是使用\"监督学习”实现一个图像分类器，来识别一张图片是猫还是狗。\n",
    "\n",
    "对于图像识别，在数据量足量大的情况下，一般使用深度学习中的卷积神经网络（Convolutional Neural Networks, CNN），而本文将从迁移学习的角度，看看如何应用现有的深度学习模型（ResNet50、InceptionV3 和 Xception），从图片中提取特征，供分类器使用。使用此方法，即无需大量学习和训练模型的时间成本，又能解决图片识别相关的大多数问题。\n",
    "\n",
    "本项目需要对测试样本进行分类，然后基于 CNN 的模型进行训练，并将结果上传至 kaggle 进行评分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "此数据集可以从 kaggle 上下载。[Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)\n",
    "下载 kaggle 猫狗数据集解压后分为 3 个文件 train.zip、 test.zip 和 sample_submission.csv。\n",
    "\n",
    "train 训练集包含了 25000 张猫狗的图片，猫狗各一半，每张图片包含图片本身和图片名。命名规则根据 “type.num.jpg” 方式命名。\n",
    "\n",
    "test 测试集包含了 12500 张猫狗的图片，没有标定是猫还是狗，每张图片命名规则根据 “num.jpg”，需要注意的是测试集编号从 1 开始，而训练集的编号从 0 开始。\n",
    "\n",
    "sample_submission.csv 需要将最终测试集的测试结果写入.csv 文件中，上传至 kaggle 进行打分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras import Input, Model\n",
    "from keras.applications import ResNet50, InceptionV3, inception_v3, Xception, xception\n",
    "from keras.layers import Lambda, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗\n",
    "在做计算机视觉的任务时，第一步很重要的事情是看看要做的是什么样的数据集，是非常干净的？还是存在各种遮挡的？猫和狗是大是小？图片清晰度一般怎么样？会不会数据集中有标注错误的数据，比例是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataRemove(path):\n",
    "    if(os.path.exists(path)):\n",
    "        os.remove(path)\n",
    "    else:\n",
    "        print(\"the target del file is not exist\")\n",
    "\n",
    "def dataStatistics(path):\n",
    "    \n",
    "    imagelist = os.listdir(path)\n",
    "    \n",
    "    total_width = 0\n",
    "    total_height = 0\n",
    "    avg_width = 0\n",
    "    avg_height = 0\n",
    "    count = 0\n",
    "    min_width = 10000\n",
    "    min_height = 10000\n",
    "    max_width = 0\n",
    "    max_height = 0\n",
    "    min_product = 100000001\n",
    "    min_product_width = 0\n",
    "    min_product_height = 0\n",
    "    \n",
    "    for x in imagelist:\n",
    "        image_name = path + \"/\" + x\n",
    "        image = Image.open(image_name)\n",
    "        width = image.size[0]\n",
    "        height = image.size[1]\n",
    "        total_width += width\n",
    "        total_height += height\n",
    "        if min_width > width:\n",
    "            min_width = width\n",
    "        if min_height > height:\n",
    "            min_height = height\n",
    "        if max_width < width:\n",
    "            max_width = width\n",
    "        if max_height < height:\n",
    "            max_height = height\n",
    "        if min_product > width * height:\n",
    "            min_product = width * height\n",
    "            min_product_width = width\n",
    "            min_product_height = height\n",
    "            if min_product < (100 * 100):\n",
    "                print(\"{} is below 100* 100 resolution，image size is {}*{}\".format(image_name, min_product_width, min_product_height))\n",
    "                dataRemove(image_name)\n",
    "        count += 1\n",
    "    print(count)\n",
    "    avg_width = total_width / count\n",
    "    avg_height = total_height / count\n",
    "    print(\"avg_width={}\\navg_height={}\\nThe total number of image is {}\".format(avg_width, avg_height, count))\n",
    "    print(\"The min width is {}\\nThe max width is {}\".format(min_width, max_width))\n",
    "    print(\"The min height is {}\\nThe max height is {}\".format(min_height, max_height))\n",
    "    print(\"The min image size is {}*{}\".format(min_product_width, min_product_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/1757.jpg is below 100* 100 resolution，image size is 95*71\n",
      "./test/12324.jpg is below 100* 100 resolution，image size is 55*104\n",
      "./test/11604.jpg is below 100* 100 resolution，image size is 60*54\n",
      "./test/5669.jpg is below 100* 100 resolution，image size is 37*50\n",
      "12500\n",
      "avg_width=404.22448\n",
      "avg_height=359.93072\n",
      "The total number of image is 12500\n",
      "The min width is 37\n",
      "The max width is 500\n",
      "The min height is 44\n",
      "The max height is 500\n",
      "The min image size is 37*50\n"
     ]
    }
   ],
   "source": [
    "dataStatistics('./test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train/dog.8987.jpg is below 100* 100 resolution，image size is 71*95\n",
      "./train/cat.2095.jpg is below 100* 100 resolution，image size is 75*79\n",
      "./train/dog.11248.jpg is below 100* 100 resolution，image size is 99*37\n",
      "./train/dog.9246.jpg is below 100* 100 resolution，image size is 65*46\n",
      "./train/dog.10747.jpg is below 100* 100 resolution，image size is 50*38\n",
      "25000\n",
      "avg_width=404.09904\n",
      "avg_height=360.47808\n",
      "The total number of image is 25000\n",
      "The min width is 42\n",
      "The max width is 1050\n",
      "The min height is 32\n",
      "The max height is 768\n",
      "The min image size is 50*38\n"
     ]
    }
   ],
   "source": [
    "dataStatistics('./train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "由于我们的数据集的文件名是以 type.num.jpg 这样的方式命名，如 cat.0.jpg，但是使用 Keras 的 ImageDataGenerator 需要将不同种类的图片分在不同的文件夹中，因此我们需要对数据集进行预处理。这里我们采取的思路是创建符号链接(symbol link)，优点是不用复制一遍图片，占用不必要的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir('train')\n",
    "# 找出所有的猫\n",
    "train_cat = filter(lambda x:x[:3] == 'cat', train_list)\n",
    "# 找出所有的狗\n",
    "train_dog = filter(lambda x:x[:3] == 'dog', train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义创建目标路径方法\n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path)\n",
    "    if folder:\n",
    "        shutil.rmtree(path)\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 训练集的 symlink 文件夹名字\n",
    "train_symlink_path = 'train-symlink'\n",
    "\n",
    "# 创建 训练集的 symlink 文件夹\n",
    "mkdir(train_symlink_path)\n",
    "\n",
    "# 分类猫图片到 train-symlink/cat 下\n",
    "os.mkdir(train_symlink_path + '/cat')\n",
    "for filename in train_cat:\n",
    "    os.symlink('../../train/' + filename, train_symlink_path + '/cat/' + filename)\n",
    "\n",
    "# 分类狗图片到  train-symlink/dog 下\n",
    "os.mkdir(train_symlink_path + '/dog')\n",
    "for filename in train_dog:\n",
    "    os.symlink('../../train/' + filename, train_symlink_path + '/dog/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 测试集的 symlink 文件夹名字 \n",
    "test_symlink_path = 'test-symlink'\n",
    "\n",
    "# 创建 测试集的 symlink 文件夹\n",
    "mkdir(test_symlink_path)\n",
    "\n",
    "# 分类测试集图片到  test-symlink/test 下\n",
    "os.symlink('../test/', test_symlink_path + '/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导出特征向量\n",
    "\n",
    "为了提高模型的表现，本项目决定使用预训练网络，最终选择了ResNet50, Xception, Inception V3 这三个模型，由于在笔记本上跑的，三个模型导出的时间耗了一天时间，时常有中途下载失败的情况。 这三个模型都是在 ImageNet 上面预训练过的，由此我们实际的预测训练会带来极高的初始精度。我们可以将多个不同的网络输出的特征向量先保存下来，后续即使是在普通笔记本上也能轻松训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "定义通用函数\n",
    "入参：模型、输入图片的大小、预处理函数\n",
    "\"\"\"\n",
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    input_tensor = Input(shape=(image_size[0], image_size[1], 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "         \n",
    "    base_model = MODEL( include_top=False, weights='imagenet', input_tensor=x)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    # 用于测试的增强配置\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # 定义了两个 generator\n",
    "    # 读取在train中找到的图片，并无限期地生成大量的增强图像数据\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "                                              \"train-symlink\", \n",
    "                                              target_size = image_size, \n",
    "                                              shuffle=False, \n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "                                             \"train-symlink\", \n",
    "                                             target_size = image_size, \n",
    "                                             shuffle=False, \n",
    "                                             batch_size=32, \n",
    "                                             class_mode='binary')\n",
    "\n",
    "    # 导出特征向量\n",
    "    train = model.predict_generator(train_generator, \n",
    "                                    math.ceil(train_generator.samples*1.0/train_generator.batch_size), \n",
    "                                    verbose=1)\n",
    "    test = model.predict_generator(test_generator, \n",
    "                                   math.ceil(test_generator.samples*1.0/test_generator.batch_size), \n",
    "                                   verbose=1)\n",
    "    \n",
    "    # 此项目选择了：ResNet50, Xception, InceptionV3 这三个模型\n",
    "    if MODEL == ResNet50:\n",
    "        model_name = \"gap_ResNet50.h5\"\n",
    "    elif MODEL == Xception:\n",
    "        model_name = \"gap_Xception.h5\"\n",
    "    elif MODEL == InceptionV3:\n",
    "        model_name = \"gap_InceptionV3.h5\"\n",
    "        \n",
    "    with h5py.File(model_name) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Python37/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "782/782 [==============================] - 3410s 4s/step\n",
      "391/391 [==============================] - 1692s 4s/step\n"
     ]
    }
   ],
   "source": [
    "write_gap(ResNet50, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 204s 2us/step\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "782/782 [==============================] - 11846s 15s/step\n",
      "391/391 [==============================] - 5768s 15s/step\n"
     ]
    }
   ],
   "source": [
    "write_gap(Xception, (299, 299), xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "782/782 [==============================] - 3319s 4s/step\n",
      "391/391 [==============================] - 1671s 4s/step\n"
     ]
    }
   ],
   "source": [
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入特征向量\n",
    "\n",
    "现在我们获得了3个特征向量文件：\n",
    "\n",
    "- gap_ResNet50.h5\n",
    "- gap_Xception.h5\n",
    "- gap_InceptionV3.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把三个模型合并在一起，每个图片就有2048*3个权重值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"gap_ResNet50.h5\", \"gap_Xception.h5\", \"gap_InceptionV3.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们基于这些权重值建立一个全连接\n",
    "\n",
    "训练深度神经网络的时候，总是会遇到两大缺点：\n",
    "\n",
    "（1）容易过拟合\n",
    "\n",
    "（2）费时\n",
    "\n",
    "Dropout可以比较有效的缓解过拟合的发生，在一定程度上达到正则化的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(X_train.shape[1:])\n",
    "x = Dropout(0.25)(inputs)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs, x)\n",
    "\n",
    "model.compile(optimizer='adadelta', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 284.00 221.00\" width=\"284pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 280,-217 280,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 56740883424 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>56740883424</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 276,-212.5 276,-166.5 0,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"64.5\" y=\"-185.8\">input_5: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"129,-166.5 129,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"129,-189.5 185,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"185,-166.5 185,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.5\" y=\"-197.3\">(None, 6144)</text>\n",
       "<polyline fill=\"none\" points=\"185,-189.5 276,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.5\" y=\"-174.3\">(None, 6144)</text>\n",
       "</g>\n",
       "<!-- 56740882864 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>56740882864</title>\n",
       "<polygon fill=\"none\" points=\".5,-83.5 .5,-129.5 275.5,-129.5 275.5,-83.5 .5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"64.5\" y=\"-102.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"128.5,-83.5 128.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"128.5,-106.5 184.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-83.5 184.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230\" y=\"-114.3\">(None, 6144)</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-106.5 275.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230\" y=\"-91.3\">(None, 6144)</text>\n",
       "</g>\n",
       "<!-- 56740883424&#45;&gt;56740882864 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>56740883424-&gt;56740882864</title>\n",
       "<path d=\"M138,-166.3799C138,-158.1745 138,-148.7679 138,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"141.5001,-139.784 138,-129.784 134.5001,-139.784 141.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 56740881352 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>56740881352</title>\n",
       "<polygon fill=\"none\" points=\"12,-.5 12,-46.5 264,-46.5 264,-.5 12,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"64.5\" y=\"-19.8\">dense_4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"117,-.5 117,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"145\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"117,-23.5 173,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"145\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"173,-.5 173,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-31.3\">(None, 6144)</text>\n",
       "<polyline fill=\"none\" points=\"173,-23.5 264,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 56740882864&#45;&gt;56740881352 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>56740882864-&gt;56740881352</title>\n",
       "<path d=\"M138,-83.3799C138,-75.1745 138,-65.7679 138,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"141.5001,-56.784 138,-46.784 134.5001,-56.784 141.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 7s 364us/step - loss: 0.0826 - acc: 0.9740 - val_loss: 0.0293 - val_acc: 0.9932\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 6s 301us/step - loss: 0.0191 - acc: 0.9937 - val_loss: 0.0199 - val_acc: 0.9936\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 6s 289us/step - loss: 0.0144 - acc: 0.9950 - val_loss: 0.0212 - val_acc: 0.9942\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 6s 296us/step - loss: 0.0129 - acc: 0.9954 - val_loss: 0.0186 - val_acc: 0.9946\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 6s 301us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0187 - val_acc: 0.9952\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 6s 306us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.0205 - val_acc: 0.9942\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 6s 293us/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0180 - val_acc: 0.9952\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 6s 298us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0194 - val_acc: 0.9942\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(X_train, y_train, batch_size=128, epochs=8, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 次 epochs，训练完不到1分钟，第一次达到了97%，后面7次均达到了99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 61us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.002, max=0.998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集结果保存至sample_submission.csv，以供提交至Kaggle上查看成绩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Dogs-vs-cats/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.998\n",
       "1   2  0.998\n",
       "2   3  0.998\n",
       "3   4  0.998\n",
       "4   5  0.002\n",
       "5   6  0.002\n",
       "6   7  0.002\n",
       "7   8  0.002\n",
       "8   9  0.002\n",
       "9  10  0.002"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "path = 'test-symlink/'\n",
    "\n",
    "# 原图\n",
    "data_generator = image.ImageDataGenerator()\n",
    "generator_data = data_generator.flow_from_directory(\n",
    "                                                                            path, \n",
    "                                                                            batch_size=32, \n",
    "                                                                            shuffle=False, \n",
    "                                                                            class_mode='binary', \n",
    "                                                                            target_size=(224, 224))\n",
    "\n",
    "for i, x in enumerate(generator_data.filenames):\n",
    "    index = int(x[x.rfind('/')+1:x.rfind('.')]) - 1\n",
    "    df.set_value(index, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred_result.csv', index=None)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://blog.csdn.net/niuwei22007/article/details/49207187\n",
    "- https://keras.io/visualization/\n",
    "- https://zhuanlan.zhihu.com/p/25978105?utm_source=weibo \n",
    "- https://keras-cn-docs.readthedocs.io/zh_CN/latest/blog/image_classification_using_very_little_data\n",
    "- https://keras-cn.readthedocs.io/en/latest/layers/pooling_layer\n",
    "- https://blog.csdn.net/shizhengxin123/article/details/72473245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
